---
title: "Statistical_Rethinking03"
author: "Robert A. Stevens"
date: "May 4, 2016"
output: html_document
---

**TODO:**

1. Run R code and check

2. Do practice problems

```{r, comment=NA}
library(rethinking)
library(StanHeaders)
```

*Statistical Rethinking: A Bayesian Course with Examples in R and Stan*

by Richard McElreath

# 3.0 Sampling the Imaginary  

```{r, comment=NA}
PrPV <- 0.95
PrPM <- 0.01
PrV <- 0.001
PrP <- PrPV*PrV + PrPM*(1 - PrV)
(PrVP <- PrPV*PrV/PrP)
```

Rethinking: The natural frequency phenomenon is not unique

Rethinking: Why statistics can't save bad science

## 3.1 Sampling from a grid-approximate posterior  

```{r, comment=NA}
p_grid <- seq(from = 0, to = 1, length.out = 1000)
prior <- rep(1, 1000)
likelihood <- dbinom(6, size = 9, prob = p_grid)
posterior <- likelihood*prior
posterior <- posterior/sum(posterior)
```

```{r, comment=NA}
samples <- sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)
```

Figure 3.1. Sampling parameter values from the posterior distribution. Left: 10,000 samples from the posterior implied by the globe tossing data and model. Right: The density of samples (vertical) at each parameter value (horizontal).

```{r, comment=NA}
plot(samples)
```

```{r, comment=NA}
dens(samples)
```

## 3.2 Sampling to summarize  

### 3.2.1 Intervals of defined boundaries

```{r, comment=NA}
# add up posterior probability where p < 0.5
sum(posterior[p_grid < 0.5])
```

```{r, comment=NA}
sum(samples < 0.5)/1e4
```

Figure 3.2. Two kinds of posterior interval. Top row: Intervals of defined boundaries. Top-left: The blue area is the posterior probability below a parameter value of 0.5. Top-right: The posterior probability between 0.5 and 0.75. Bottom row: Intervals of defined mass. Bottom-left: Lower 80% posterior probability exists below a parameter value of about 0.75. Bottom-right: Middle 80% posterior probability lies between the 10% and 90% quantities.

```{r, comment=NA}
sum(samples > 0.5 & samples < 0.75)/1e4
```

Overthinking: Counting with sum

### 3.2.2 Intervals of defined mass

```{r, comment=NA}
quantile(samples, 0.8)
```

```{r, comment=NA}
quantile(samples, c(0.1, 0.9))
```

```{r, comment=NA}
p_grid <- seq(from = 0, to = 1, length.out = 1000)
prior <- rep(1, 1000)
likelihood <- dbinom(3, size = 3, prob = p_grid)
posterior <- likelihood*prior
posterior <- posterior/sum(posterior)
samples <- sample(p_grid, size = 1e4, replace = TRUE, prob = posterior)
```

```{r, comment=NA}
PI(samples, prob = 0.5)
```

Figure 3.3. The difference between percentile an highest posterior density confidence intervals. The posterior density here corresponds to a flat prior and observing three water samples in three total tosses of the globe. Left: 50% percentile interval. This interval assigns equal mass (25%) to both the left and right tail. As a result, it omits the most probable parameter value, p = 1. Right: 50% highest posterior density interval, HPDI. This interval finds the narrowest region with 50% of the posterior probability. Such a region always includes the most probable parameter value.

```{r, comment=NA}
HPDI(samples, prob = 0.5)
```

Rethinking: Why 95%

Rethinking:  What do confidence intervals mean?

### 3.2.3 Point estimates

```{r, comment=NA}
p_grid[which.max(posterior)]
```

```{r, comment=NA}
chainmode(samples, adj = 0.01)
```

```{r, comment=NA}
mean(samples)
median(samples)
```

Figure 3.4. Point estimates and loss functions. Left: Posterior distribution (blue) aster observing 3 water in 3 tosses of the globe. Vertical lines show the locations of the mode, median, and mean. Each point implies a different loss function. Right: Expected loss under the rule that loss is proportional to absolute distance of decision (horizontal axis) from the true value. The point marks the value of p that minimizes the expected loss, the posterior median.

```{r, comment=NA}
sum(posterior*abs(0.5 - p_grid))
```

```{r, comment=NA}
loss <- sapply(p_grid, function(d) sum(posterior*abs(d - p_grid)))
```

```{r, comment=NA}
p_grid[which.min(loss)]
```

## 3.3 Sampling to simulate prediction  

### 3.3.1 Dummy data

```{r, comment=NA}
dbinom(0:2, size = 2, prob = 0.7)
```

```{r, comment=NA}
rbinom(1, size = 2, prob = 0.7)
```

```{r, comment=NA}
rbinom(10, size = 2, prob = 0.7)
```

```{r, comment=NA}
dummy_w <- rbinom(1e5, size = 2, prob = 0.7)
table(dummy_w)/1e5
```

```{r, comment=NA}
dummy_w <- rbinom(1e5, size = 9, prob = 0.7)
simplehist(dummy_w, xlab = "dummy water count")
```

Figure 3.5. Distribution of simulated sample observations form 9 tosses of the globe. These samples assume the proportion of water is 0.7.

Rethinking: Sampling distributions

### 3.3.2 Model checking

#### 3.3.2.1 Did the software work?

#### 3.3.2.2 Is the model adequate?

Figure 3.6. Simulating predictions from the total posterior. Top: The familiar posterior distribution for the globe tossing data. Ten example parameter values are marked by the vertical lines. Values with greater posterior probability indicated by the thicker lines. Middle row: Each of the ten parameter values implies a unique sampling distribution of predictions. Bottom: Combining simulated observation distributions for all parameter values (not just the ten shown), each weighted by its posterior probability, produces the posterior predictive distribution. This distribution propagates uncertainty about parameter to uncertainty about prediction.

```{r, comment=NA}
w <- rbinom(1e4, size = 9, prob = 0.6)
```

```{r, comment=NA}
w <- rbinom(1e4, size = 9, prob = samples)
```

Figure 3.7. Alternative views of the same posterior predictive distribution (see Figure 3.6). Instead of considering the data as the model saw it, as a sum of water samples, now we view the data as both the length of the maximum run of water or land (left) and the number of switches between water and land samples (right). Observed values highlighted in blue. While the simulated predictions are consistent with the run length (3 water in a row), they are much less consistent with the frequent switches (6 switches in 9 tosses).

Rethinking: What does more extreme mean?

## 3.4 Summary  

## 3.5 Practice 

```{r, comment=NA}
p_grid <- seq(from = 0, to = 1, length.out = 1000)
prior <- rep(1, 1000)
likelihood <- dbinom(6, size = 9, prob = p_grid)
posterior <- likelihood*prior
posterior <- posterior/sum(posterior)
set.seed(100)
samples <- sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)
```

3E1

3E2

3E3

3E4

3E5

3E6

3E7

3M1

3M2

3M3

3M4

3M5

```{r, comment=NA}
birth1 <- c(1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 
            0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 
            0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 
            0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0,
            1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,
            1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1)
birth2 <- c(0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0,
            1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,
            1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1,
            1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0,
            1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,
            1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0)
```

```{r, comment=NA}
data(homeworkch3)
```

```{r, comment=NA}
sum(birth1) + sum(birth2)
```

3H1

3H2

3H3

3H4

3H5
